{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0+cu124\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import Tensor \n",
    "print(torch.__version__)\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heterogeneous graph creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using existing file ml-latest-small.zip\n",
      "Extracting ./data\\ml-latest-small.zip\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import download_url, extract_zip\n",
    "\n",
    "url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
    "extract_zip(download_url(url, './data'), './data')\n",
    "\n",
    "movies_path = './data/ml-latest-small/movies.csv'\n",
    "ratings_path = './data/ml-latest-small/ratings.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movieId                               title  \\\n",
      "0        1                    Toy Story (1995)   \n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                        genres  \n",
      "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
      "1                   Adventure|Children|Fantasy  \n",
      "2                               Comedy|Romance  \n",
      "3                         Comedy|Drama|Romance  \n",
      "4                                       Comedy  \n",
      "   userId  movieId  rating  timestamp\n",
      "0       1        1     4.0  964982703\n",
      "1       1        3     4.0  964981247\n",
      "2       1        6     4.0  964982224\n",
      "3       1       47     5.0  964983815\n",
      "4       1       50     5.0  964982931\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Look through the .csv data files\n",
    "print(pd.read_csv(movies_path).head())\n",
    "print(pd.read_csv(ratings_path).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies.csv\n",
      "   movieId                                       genres\n",
      "0        1  Adventure|Animation|Children|Comedy|Fantasy\n",
      "1        2                   Adventure|Children|Fantasy\n",
      "2        3                               Comedy|Romance\n",
      "3        4                         Comedy|Drama|Romance\n",
      "4        5                                       Comedy\n",
      "\n",
      "ratings.csv\n",
      "   userId  movieId\n",
      "0       1        1\n",
      "1       1        3\n",
      "2       1        6\n",
      "3       1       47\n",
      "4       1       50\n"
     ]
    }
   ],
   "source": [
    "# view only relevant info in the .csv files that you are considering here\n",
    "print('movies.csv')\n",
    "print(pd.read_csv(movies_path)[[\"movieId\", \"genres\"]].head())\n",
    "print()\n",
    "print(\"ratings.csv\")\n",
    "print(pd.read_csv(ratings_path)[[\"userId\", \"movieId\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9742\n",
      "         Action  Adventure  Drama  Horror\n",
      "movieId                                  \n",
      "1             0          1      0       0\n",
      "2             0          1      0       0\n",
      "3             0          0      0       0\n",
      "4             0          0      1       0\n",
      "5             0          0      0       0\n"
     ]
    }
   ],
   "source": [
    "# Extract the feature vectors for movie-nodes\n",
    "\n",
    "# Load the entire movie data frame into memory:\n",
    "movies_df = pd.read_csv(movies_path, index_col='movieId')\n",
    "print(len(movies_df)) # 9742 movies\n",
    "\n",
    "# Split genres and convert into indicator variables:\n",
    "genres = movies_df['genres'].str.get_dummies('|')\n",
    "print(genres[[\"Action\", \"Adventure\", \"Drama\", \"Horror\"]].head())\n",
    "\n",
    "# Use genres as movie input features:\n",
    "movie_feat = torch.from_numpy(genres.values).to(torch.float)\n",
    "assert movie_feat.size() == (9742, 20)  # 9742 movies, 20 genres in total.\n",
    "# print(movie_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating  timestamp\n",
      "0       1        1     4.0  964982703\n",
      "1       1        3     4.0  964981247\n",
      "2       1        6     4.0  964982224\n",
      "3       1       47     5.0  964983815\n",
      "4       1       50     5.0  964982931\n",
      "(100836, 4)\n",
      "(610,)\n",
      "   userId  mappedID\n",
      "0       1         0\n",
      "1       2         1\n",
      "2       3         2\n",
      "3       4         3\n",
      "4       5         4\n",
      "================================================\n",
      "   movieId  mappedID\n",
      "0        1         0\n",
      "1        2         1\n",
      "2        3         2\n",
      "3        4         3\n",
      "4        5         4\n"
     ]
    }
   ],
   "source": [
    "# Get the edge_index between uses and movies\n",
    "\n",
    "# Step 1: from the ratings.csv, create unique users's & movie's ID\n",
    "# Step 1: 610 users (0 --> 609) and 9742 movies (0 --> 9741)\n",
    "\n",
    "ratings_df = pd.read_csv(ratings_path)\n",
    "print(ratings_df.head())\n",
    "print(ratings_df.shape)\n",
    "\n",
    "# Create a mapping from unique user indices to range [0, num_user_nodes):\n",
    "unique_user_id = ratings_df['userId'].unique()\n",
    "print(unique_user_id.shape)\n",
    "\n",
    "unique_user_id = pd.DataFrame(data={\n",
    "    'userId': unique_user_id,\n",
    "    'mappedID': pd.RangeIndex(len(unique_user_id)),\n",
    "})\n",
    "\n",
    "print(unique_user_id.head())\n",
    "# print(unique_user_id)\n",
    "\n",
    "print(\"================================================\")\n",
    "# print(movies_df.head())\n",
    "\n",
    "# Create a mapping from unique movie indices to range [0, num_movie_nodes):\n",
    "unique_movie_id = pd.DataFrame(data={\n",
    "    'movieId': movies_df.index,\n",
    "    'mappedID': pd.RangeIndex(len(movies_df)),\n",
    "})\n",
    "\n",
    "print(unique_movie_id.head())\n",
    "# print(unique_movie_id.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100836, 2)\n",
      "torch.Size([100836])\n",
      "torch.Size([100836])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([  0,   2,   5,  43,  46,  62,  89,  97, 124, 130])\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Perform merges to be able to map userId and movieId in ratings.csv to unique userId and movieId\n",
    "\n",
    "ratings_user_id = pd.merge(ratings_df['userId'], unique_user_id,\n",
    "                            left_on='userId', right_on='userId', how='left')\n",
    "print(ratings_user_id.shape) # left merge with ratings to map userId'%%SVG\n",
    "# print(ratings_user_id)\n",
    "ratings_user_id = torch.from_numpy(ratings_user_id['mappedID'].values) #100836\n",
    "print(ratings_user_id.shape)\n",
    "\n",
    "ratings_movie_id = pd.merge(ratings_df['movieId'], unique_movie_id,\n",
    "                            left_on='movieId', right_on='movieId', how='left')\n",
    "ratings_movie_id = torch.from_numpy(ratings_movie_id['mappedID'].values)\n",
    "print(ratings_movie_id.shape)\n",
    "\n",
    "print(ratings_user_id[:10])\n",
    "print(ratings_movie_id[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,    0,    0,  ...,  609,  609,  609],\n",
      "        [   0,    2,    5,  ..., 9462, 9463, 9503]])\n",
      "torch.Size([2, 100836])\n"
     ]
    }
   ],
   "source": [
    "# Step 3: With this, we are ready to construct our `edge_index` in COO format\n",
    "# following PyG semantics:\n",
    "edge_index_user_to_movie = torch.stack([ratings_user_id, ratings_movie_id], dim=0)\n",
    "assert edge_index_user_to_movie.size() == (2, 100836)\n",
    "print(edge_index_user_to_movie)\n",
    "print(edge_index_user_to_movie.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Construct the HeteroData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  user={ node_id=[610] },\n",
      "  movie={\n",
      "    node_id=[9742],\n",
      "    x=[9742, 20],\n",
      "  },\n",
      "  (user, rates, movie)={ edge_index=[2, 100836] },\n",
      "  (movie, rev_rates, user)={ edge_index=[2, 100836] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "data = HeteroData()\n",
    "\n",
    "# Save node indices:\n",
    "data[\"user\"].node_id = torch.arange(len(unique_user_id))\n",
    "data[\"movie\"].node_id = torch.arange(len(movies_df))\n",
    "\n",
    "# Add the node features and edge indices:\n",
    "data[\"movie\"].x = movie_feat\n",
    "data[\"user\", \"rates\", \"movie\"].edge_index = edge_index_user_to_movie\n",
    "\n",
    "# We also need to make sure to add the reverse edges from movies to users\n",
    "# in order to let a GNN be able to pass messages in both directions.\n",
    "# We can leverage the `T.ToUndirected()` transform for this from PyG:\n",
    "\n",
    "data = T.ToUndirected()(data)\n",
    "\n",
    "print(data)\n",
    "\n",
    "assert data.node_types == [\"user\", \"movie\"]\n",
    "assert data.edge_types == [(\"user\", \"rates\", \"movie\"),\n",
    "                           (\"movie\", \"rev_rates\", \"user\")]\n",
    "assert data[\"user\"].num_nodes == 610\n",
    "assert data[\"user\"].num_features == 0\n",
    "assert data[\"movie\"].num_nodes == 9742\n",
    "assert data[\"movie\"].num_features == 20\n",
    "assert data[\"user\", \"rates\", \"movie\"].num_edges == 100836\n",
    "assert data[\"movie\", \"rev_rates\", \"user\"].num_edges == 100836"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining edge-level training splits\n",
    "- Note: All training edges (message passing + supervision = 80670) are available in the validation/test set for evaluation as can be seen below\n",
    "- RandomLinkSplit: Performs an edge-level random split into training, val, test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "==============\n",
      "HeteroData(\n",
      "  user={ node_id=[610] },\n",
      "  movie={\n",
      "    node_id=[9742],\n",
      "    x=[9742, 20],\n",
      "  },\n",
      "  (user, rates, movie)={\n",
      "    edge_index=[2, 56469],\n",
      "    edge_label=[24201],\n",
      "    edge_label_index=[2, 24201],\n",
      "  },\n",
      "  (movie, rev_rates, user)={ edge_index=[2, 56469] }\n",
      ")\n",
      "\n",
      "Validation data:\n",
      "================\n",
      "HeteroData(\n",
      "  user={ node_id=[610] },\n",
      "  movie={\n",
      "    node_id=[9742],\n",
      "    x=[9742, 20],\n",
      "  },\n",
      "  (user, rates, movie)={\n",
      "    edge_index=[2, 80670],\n",
      "    edge_label=[30249],\n",
      "    edge_label_index=[2, 30249],\n",
      "  },\n",
      "  (movie, rev_rates, user)={ edge_index=[2, 80670] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# For this, we first split the set of edges into\n",
    "# training (80%), validation (10%), and testing edges (10%).\n",
    "# Across the training edges, we use 70% of edges for message passing,\n",
    "# and 30% of edges for supervision.\n",
    "# We further want to generate fixed negative edges for evaluation with a ratio of 2:1.\n",
    "# Negative edges during training will be generated on-the-fly, so we don't want to\n",
    "# add them to the graph right away.\n",
    "# Overall, we can leverage the `RandomLinkSplit()` transform for this from PyG:\n",
    "transform = T.RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    disjoint_train_ratio=0.3,\n",
    "    neg_sampling_ratio=2.0, \n",
    "    add_negative_train_samples=False,\n",
    "    edge_types=(\"user\", \"rates\", \"movie\"),\n",
    "    rev_edge_types=(\"movie\", \"rev_rates\", \"user\"),\n",
    ")\n",
    "train_data, val_data, test_data = transform(data)\n",
    "print(\"Training data:\")\n",
    "print(\"==============\")\n",
    "print(train_data)\n",
    "print()\n",
    "print(\"Validation data:\")\n",
    "print(\"================\")\n",
    "print(val_data)\n",
    "\n",
    "assert train_data[\"user\", \"rates\", \"movie\"].num_edges == 56469 # training edges\n",
    "assert train_data[\"user\", \"rates\", \"movie\"].edge_label_index.size(1) == 24201 # supervision edges\n",
    "assert train_data[\"movie\", \"rev_rates\", \"user\"].num_edges == 56469\n",
    "# No negative edges added:\n",
    "assert train_data[\"user\", \"rates\", \"movie\"].edge_label.min() == 1\n",
    "assert train_data[\"user\", \"rates\", \"movie\"].edge_label.max() == 1\n",
    "\n",
    "assert val_data[\"user\", \"rates\", \"movie\"].num_edges == 80670\n",
    "assert val_data[\"user\", \"rates\", \"movie\"].edge_label_index.size(1) == 30249\n",
    "assert val_data[\"movie\", \"rev_rates\", \"user\"].num_edges == 80670\n",
    "# Negative edges with ratio 2:1:\n",
    "assert val_data[\"user\", \"rates\", \"movie\"].edge_label.long().bincount().tolist() == [20166, 10083]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining mini-batch loaders\n",
    "- loader.LinkNeighborLoader: samples multiple hops from both ends of a link (edge) and creates a subgraph from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 24201])\n",
      "tensor([[ 558,  176,  176,  ...,  602,  462,  245],\n",
      "        [ 418, 7324, 6273,  ..., 1797, 4360, 7456]])\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.])\n",
      "torch.Size([24201])\n",
      "----------\n",
      "HeteroData(\n",
      "  user={\n",
      "    node_id=[607],\n",
      "    n_id=[607],\n",
      "    num_sampled_nodes=[3],\n",
      "  },\n",
      "  movie={\n",
      "    node_id=[2760],\n",
      "    x=[2760, 20],\n",
      "    n_id=[2760],\n",
      "    num_sampled_nodes=[3],\n",
      "  },\n",
      "  (user, rates, movie)={\n",
      "    edge_index=[2, 16988],\n",
      "    edge_label=[384],\n",
      "    edge_label_index=[2, 384],\n",
      "    e_id=[16988],\n",
      "    num_sampled_edges=[2],\n",
      "    input_id=[128],\n",
      "  },\n",
      "  (movie, rev_rates, user)={\n",
      "    edge_index=[2, 7624],\n",
      "    e_id=[7624],\n",
      "    num_sampled_edges=[2],\n",
      "  }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# In the first hop, we sample at most 20 neighbors.\n",
    "# In the second hop, we sample at most 10 neighbors.\n",
    "# In addition, during training, we want to sample negative edges on-the-fly with\n",
    "# a ratio of 2:1.\n",
    "# We can make use of the `loader.LinkNeighborLoader` from PyG:\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "# Define seed edges\n",
    "edge_label_index = train_data[\"user\", \"rates\", \"movie\"].edge_label_index # supervision/positive edges or samples\n",
    "print(edge_label_index.shape)\n",
    "print(edge_label_index)\n",
    "\n",
    "edge_label = train_data[\"user\", \"rates\", \"movie\"].edge_label # all 1's as positive edges\n",
    "print(edge_label)\n",
    "print(edge_label.shape)\n",
    "print('----------')\n",
    "\n",
    "train_loader = LinkNeighborLoader(\n",
    "    data = train_data,\n",
    "    num_neighbors=[20,10],\n",
    "    neg_sampling_ratio=2.0,\n",
    "    edge_label_index=((\"user\", \"rates\", \"movie\"), edge_label_index),\n",
    "    edge_label=edge_label,\n",
    "    batch_size=128, # takes 128 positive edges, 2*128 negative edges dynamically (384 edges)\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# Inspect a sample:\n",
    "sampled_data = next(iter(train_loader))\n",
    "print(sampled_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heterogeneous Link-level GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={ node_id=[610] },\n",
       "  movie={\n",
       "    node_id=[9742],\n",
       "    x=[9742, 20],\n",
       "  },\n",
       "  (user, rates, movie)={ edge_index=[2, 100836] },\n",
       "  (movie, rev_rates, user)={ edge_index=[2, 100836] }\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data \n",
    "# data[\"user\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(610, 9742)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"user\"].num_nodes, data[\"movie\"].num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (movie_lin): Linear(in_features=20, out_features=64, bias=True)\n",
      "  (user_emb): Embedding(610, 64)\n",
      "  (movie_emb): Embedding(9742, 64)\n",
      "  (gnn): GraphModule(\n",
      "    (conv1): ModuleDict(\n",
      "      (user__rates__movie): SAGEConv(64, 64, aggr=mean)\n",
      "      (movie__rev_rates__user): SAGEConv(64, 64, aggr=mean)\n",
      "    )\n",
      "    (conv2): ModuleDict(\n",
      "      (user__rates__movie): SAGEConv(64, 64, aggr=mean)\n",
      "      (movie__rev_rates__user): SAGEConv(64, 64, aggr=mean)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Classifier()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# Our final classifier applies the dot-product between source and destination\n",
    "# node embeddings to derive edge-level predictions:\n",
    "class Classifier(torch.nn.Module):\n",
    "    def forward(self, x_user, x_movie, edge_label_index):\n",
    "        # Convert node embeddings to edge-level representations:\n",
    "        # (user rates movie): edge_index so edge_index[0] is userId and edge_index[1] is movie \n",
    "        edge_feat_user = x_user[edge_label_index[0]]\n",
    "        edge_feat_movie = x_movie[edge_label_index[1]]\n",
    "\n",
    "        # print(edge_feat_user.shape, edge_feat_movie.shape)\n",
    "\n",
    "        # Apply dot product\n",
    "        return (edge_feat_user * edge_feat_movie).sum(dim=-1)\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Since the dataset does not come with rich features, we also learn two\n",
    "        # embedding matrices for users and movies:\n",
    "        self.movie_lin = torch.nn.Linear(20, hidden_channels)\n",
    "        self.user_emb = torch.nn.Embedding(data[\"user\"].num_nodes, hidden_channels) # create embedding for users (look-up table like NLP)\n",
    "        self.movie_emb = torch.nn.Embedding(data[\"movie\"].num_nodes, hidden_channels)\n",
    "\n",
    "        # Instantiate homogeneous GNN\n",
    "        self.gnn = GNN(hidden_channels)\n",
    "\n",
    "        # convert GNN model into a heterogeneous variant:\n",
    "        self.gnn = to_hetero(self.gnn, metadata=data.metadata())\n",
    "\n",
    "        self.classifier = Classifier()\n",
    "    \n",
    "    def forward(self, data: HeteroData):\n",
    "        # user nodeId: 0 -> 609\n",
    "        # movie nodeId: 0 -> 9741\n",
    "        # movie x (features): 0/1 20-dim of genre\n",
    "        # print(data)\n",
    "        \n",
    "        x_dict = {\n",
    "            \"user\": self.user_emb(data[\"user\"].node_id), # get from nn.Embedding\n",
    "            \"movie\": self.movie_lin(data[\"movie\"].x) + self.movie_emb(data[\"movie\"].node_id) # get from nn.Embedding\n",
    "        }\n",
    "\n",
    "        # `x_dict` holds feature matrices of all node types\n",
    "        # `edge_index_dict` holds all edge indices of all edge types -- Undirected\n",
    "        # edge_index_dict holds only \"message passing\" edges\n",
    "        x_dict = self.gnn(x_dict, data.edge_index_dict) \n",
    "\n",
    "        # edge_label_index hold one direction (user rates movie) \"supervision\" edges\n",
    "        # print(data[\"user\",\"rates\",\"movie\"].edge_label_index.shape)\n",
    "        # fsjhbf\n",
    "        \n",
    "        pred = self.classifier(\n",
    "            x_dict[\"user\"],\n",
    "            x_dict[\"movie\"],\n",
    "            data[\"user\",\"rates\",\"movie\"].edge_label_index\n",
    "        )\n",
    "\n",
    "        return pred\n",
    "    \n",
    "model = Model(hidden_channels=64)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190/190 [00:01<00:00, 121.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, loss: 0.4394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190/190 [00:01<00:00, 129.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, loss: 0.3488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190/190 [00:01<00:00, 130.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, loss: 0.3259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190/190 [00:01<00:00, 123.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, loss: 0.3138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190/190 [00:01<00:00, 130.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, loss: 0.2975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm \n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'Device: {device}')\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(1,6):\n",
    "    total_loss = total_examples = 0\n",
    "    for sampled_data in tqdm.tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        sampled_data = sampled_data.to(device)\n",
    "        pred = model(sampled_data)\n",
    "        ground_truth = sampled_data[\"user\", \"rates\", \"movie\"].edge_label\n",
    "        loss = F.binary_cross_entropy_with_logits(pred,ground_truth)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss) * pred.numel()\n",
    "        total_examples += pred.numel()\n",
    "    print(f\"Epoch: {epoch:03d}, loss: {total_loss / total_examples:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation on val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  user={\n",
      "    node_id=[607],\n",
      "    n_id=[607],\n",
      "    num_sampled_nodes=[3],\n",
      "  },\n",
      "  movie={\n",
      "    node_id=[2655],\n",
      "    x=[2655, 20],\n",
      "    n_id=[2655],\n",
      "    num_sampled_nodes=[3],\n",
      "  },\n",
      "  (user, rates, movie)={\n",
      "    edge_index=[2, 18540],\n",
      "    edge_label=[384],\n",
      "    edge_label_index=[2, 384],\n",
      "    e_id=[18540],\n",
      "    num_sampled_edges=[2],\n",
      "    input_id=[384],\n",
      "  },\n",
      "  (movie, rev_rates, user)={\n",
      "    edge_index=[2, 7715],\n",
      "    e_id=[7715],\n",
      "    num_sampled_edges=[2],\n",
      "  }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define the validation seed edges:\n",
    "edge_label_index = val_data[\"user\", \"rates\", \"movie\"].edge_label_index\n",
    "edge_label = val_data[\"user\", \"rates\", \"movie\"].edge_label\n",
    "\n",
    "val_loader = LinkNeighborLoader(\n",
    "    data=val_data,\n",
    "    num_neighbors=[20, 10],\n",
    "    edge_label_index=((\"user\", \"rates\", \"movie\"), edge_label_index),\n",
    "    edge_label=edge_label,\n",
    "    batch_size=3 * 128,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "sampled_data = next(iter(val_loader))\n",
    "print(sampled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 153.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val score: 0.9283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "preds = []\n",
    "ground_truths = []\n",
    "for sampled_data in tqdm.tqdm(val_loader):\n",
    "    with torch.no_grad():\n",
    "        sampled_data = sampled_data.to(device)\n",
    "        preds.append(model(sampled_data))\n",
    "        ground_truths.append(sampled_data[\"user\",\"rates\",\"movie\"].edge_label)\n",
    "        # loss = F.binary_cross_entropy_with_logits(pred,ground_truth)\n",
    "pred = torch.cat(preds, dim=0).cpu().numpy()\n",
    "ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()\n",
    "auc = roc_auc_score(ground_truth, pred)\n",
    "print(f\"Val score: {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = [torch.tensor([1,2]),torch.tensor([3,4])]\n",
    "torch.cat(preds, dim=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn_mol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
